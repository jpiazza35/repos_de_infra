# Databricks Workspace Configuration

## **Design Constraints for Databricks Configuration Management**

Our approach to managing Databricks configuration is subject to several design constraints, primarily divided between account-level configuration and workspace-level management.

### Account-Level Configuration
Account-level configurations, such as workspace provisioning, network settings, and user/group management, are handled by DevOps. This is managed separately in our [DevOps repository](https://github.com/clinician-nexus/data-platform-devops-iac/tree/main/terraform/databricks). Key points include:
- Groups are provisioned in Active Directory by the IT team.
- These groups are then synchronized to Databricks through this module.
- IT is responsible for the ongoing management of group memberships in Active Directory.

### Workspace-Level Management
The `data-platform` team is responsible for managing all aspects **inside** a Databricks workspace. Our responsibilities extend to deploying a variety of workspace-specific resources. Key aspects include:

- **Storage Configurations**: Setting up and managing storage options within the workspace, ensuring they align with data handling and processing requirements.

- **Data Catalogs and Schemas**: Creating and maintaining data catalogs and schemas that organize and structure the data effectively for easy access and analysis.

- **Service Principals**: Deploying service principals, which are automated users, to enable programmatic access and operations within the Databricks environment.

- **Workspace-Specific Databricks Resources**: Managing any other Databricks resources that are specific to a workspace. This could include clusters, jobs, notebooks, and more, depending on the workspace's needs.

- **Security and Access Control**: Importantly, all these resources must be secured according to the group memberships and roles defined in the account-level configuration. We ensure that the appropriate permissions and access controls are in place, reflecting the group structures provisioned in Active Directory by IT and synchronized to Databricks.

Our role is to ensure that everything within the workspace is optimally configured, secure, and aligned with both the broader organizational policies and the specific needs of our workspace users.


### Infrastructure-as-Code (IaC) Approach
We employ Infrastructure-as-Code (IaC) to manage Unity Catalog, aiming for consistency and auditability across workspaces. Key aspects include:
- Avoidance of "click-ops"; all configurations are codified.
- Terraform serves as the primary tool for transforming Unity Catalog (and other Databricks configurations) into IaC.

### Critical Terraform Resources
In our Terraform setup, two resources are particularly pivotal:

1. [`databricks_permissions`](https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/permissions#data-access-with-unity-catalog)
2. [`databricks_grants`](https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/grant)

The configuration of `databricks_permissions` is crucial because it **overwrites** any existing permissions of the same type unless imported. Changes made outside Terraform are also reset unless they are reflected in the configuration. This is a key reason why catalogs and schemas must be managed exclusively in this repository:

- **Catalogs and Schemas Management**: Since `databricks_permissions` can overwrite existing settings, catalogs and schemas need to be managed centrally to maintain consistency and control. This ensures that permissions are set and modified in a controlled manner, preventing conflicts or accidental overwrites.

- **Tables Management**: While catalogs and schemas are managed within this repository, tables are considered application-specific and are therefore outside its scope. Each application repository is responsible for the lifecycle and permissions of its tables. However, these tables operate within the inherited permission sets from the catalogs and schemas. This delineation ensures that application teams have the flexibility to manage their tables while adhering to the broader security and access framework established at the catalog and schema levels.

Our approach guarantees a structured and secure management of Databricks resources, aligning with our broader goals of consistency, auditability, and controlled access in the workspace.

## Process for Requesting Access to a Catalog or Schema

1. **Identify the Required Access**:
   - The user or team should first clearly identify the specific catalog or schema they need access to and the type of access required (e.g., read, write, admin).

2. **Submit an Access Request**:
   - The request should be made through a predefined channel, such as a ticketing system or an internal request form, including details such as the user's identity, the specific catalog or schema, and the type of access needed.

3. **Approval from Data-Platform Team**:
   - The `data-platform` team reviews the request for its validity and alignment with organizational policies. This may involve verifying the requester's role and the necessity of the access.

4. **Group Membership Verification**:
   - If the access request is approved, the team will check if the requester is part of an appropriate Active Directory group already synchronized to Databricks. If not, the requester may need to contact IT to be added to the relevant group.

5. **Update Terraform Configuration**:
   - The `data-platform` team updates the Terraform configuration to reflect the new access permissions. This step involves modifying the `databricks_permissions` and/or `databricks_grants` resources to include the new access rules.

6. **Apply Terraform Changes**:
   - The updated Terraform configuration is applied to update the permissions in the Databricks workspace.

7. **Notify the Requester**:
   - After successfully applying the Terraform changes, the requester is notified that they now have access to the specified catalog or schema.

8. **Monitoring and Compliance**:
   - Regular audits and compliance checks will be conducted to ensure that access permissions are in line with the organizational security policies.

This process ensures controlled, auditable access to catalogs and schemas, aligning with security and management policies and leveraging Infrastructure-as-Code for systematic application and tracking.


**_Note_** This process is not automated yet - reach out to #data-platform to begin a request, but the above is the general flow.
